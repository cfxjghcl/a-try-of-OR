import streamlit as st
import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import os, sys
import matplotlib.font_manager as fm
import plotly.express as px

# --- sys.path modification (if you still need it here, though utils import should handle it) ---
# current_page_script_dir = os.path.dirname(os.path.abspath(__file__))
# streamlit_app_dir = os.path.dirname(current_page_script_dir)
# project_root = os.path.dirname(streamlit_app_dir)
# if project_root not in sys.path:
#     sys.path.insert(0, project_root)
# --- end sys.path modification ---


# --- PAGE CONFIGURATION (MOVED TO THE TOP) ---
# Ensure this is called only once per app run for this page
if 'page_config_called_skills_majors' not in st.session_state:
    st.set_page_config(page_title="æŠ€èƒ½ä¸ä¸“ä¸šæ´å¯Ÿ", layout="wide", page_icon="ğŸ› ï¸")
    st.session_state.page_config_called_skills_majors = True
# --- END PAGE CONFIGURATION ---


try:
    # Assuming your project structure is correct, direct import from utils should work
    # if the streamlit_app directory is the root for streamlit run, or project_root is in sys.path
    from streamlit_app.utils import (  # Changed to be more explicit if utils is in streamlit_app
        load_json_data,
        preprocess_jobs_data,
        extract_skills_from_text_series,
        get_skill_frequency,
        get_word_counts_from_list_column,
        get_top_n_counts,
        get_skill_cooccurrence_optimized,
        SKILL_REGEX_PATTERNS,
        plot_bar_chart,
        JOBS_FILE,
        ASSETS_DIR,
        get_average_salary,
    )
except ImportError as e:
    # Fallback if the above doesn't work (e.g. running script directly from pages folder)
    # This assumes utils.py is in a directory named 'utils' at the same level as 'pages'
    # or that the sys.path modification at the top of this script is active and correct.
    # For a multi-page app, it's better to structure imports from the app's root.
    try:
        from utils import ( # Try direct import if sys.path is already set up
            load_json_data,
            preprocess_jobs_data,
            extract_skills_from_text_series,
            get_skill_frequency,
            get_word_counts_from_list_column,
            get_top_n_counts,
            get_skill_cooccurrence_optimized,
            SKILL_REGEX_PATTERNS,
            plot_bar_chart,
            JOBS_FILE,
            ASSETS_DIR,
            get_average_salary,
        )
    except ImportError:
        st.error(f"Failed to import from utils.py: {e}. Ensure it's in the correct path relative to your Streamlit app's root and all names are defined.")
        st.error(f"Current sys.path: {sys.path}")
        st.error(f"Current working directory: {os.getcwd()}")
        st.stop()


@st.cache_data
def get_chinese_font_path_dynamically():
    # ... (rest of your function)
    if 'ASSETS_DIR' in globals() and os.path.exists(ASSETS_DIR):
        preferred_fonts_in_assets = ['simhei.ttf', 'msyh.ttf', 'SimHei.ttf', 'Microsoft YaHei.ttf']
        for font_name in preferred_fonts_in_assets:
            asset_font_path = os.path.join(ASSETS_DIR, font_name)
            if os.path.exists(asset_font_path): return asset_font_path
    font_family_preferences = ['SimHei', 'Microsoft YaHei', 'PingFang SC', 'WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'Source Han Sans SC', 'STHeiti', 'Arial Unicode MS', 'Droid Sans Fallback', 'sans-serif']
    for font_family in font_family_preferences:
        try:
            font_path = fm.findfont(fm.FontProperties(family=font_family))
            if font_path: return font_path
        except Exception: continue
    return None

FONT_PATH_FOR_WORDCLOUD = get_chinese_font_path_dynamically()

@st.cache_data
def generate_wordcloud_from_freq_dict(freq_dict, title="è¯äº‘å›¾", max_words=100):
    # ... (rest of your function)
    if not freq_dict:
        return None
    if FONT_PATH_FOR_WORDCLOUD is None and 'font_missing_warning_shown' not in st.session_state:
        st.warning("æœªèƒ½è‡ªåŠ¨æ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ã€‚è¯äº‘å›¾ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤ºã€‚å»ºè®®ï¼šå°†ä¸­æ–‡å­—ä½“æ–‡ä»¶ï¼ˆå¦‚ simhei.ttfï¼‰æ”¾ç½®åœ¨é¡¹ç›®çš„ `streamlit_app/assets/` ç›®å½•ä¸‹ã€‚")
        st.session_state.font_missing_warning_shown = True # Set flag after showing once
    try:
        wordcloud = WordCloud(font_path=FONT_PATH_FOR_WORDCLOUD, width=800, height=400, background_color='white', max_words=max_words, collocations=False).generate_from_frequencies(freq_dict)
        return wordcloud
    except Exception as e:
        st.error(f"ç”Ÿæˆè¯äº‘å›¾ '{title}' å¤±è´¥: {e}")
        if "ValueError: We need at least 1 word to plot a word cloud, got 0." in str(e): st.info(f"è¯äº‘å›¾ '{title}': è¿‡æ»¤åæ²¡æœ‰è¶³å¤Ÿçš„è¯æ¥ç”Ÿæˆè¯äº‘ã€‚")
        return None


def display_wordcloud(wc, title):
    # ... (rest of your function)
    if wc:
        fig, ax = plt.subplots(figsize=(10, 5)); ax.imshow(wc, interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)
    else: st.info(f"æ— æ³•ä¸º '{title}' ç”Ÿæˆè¯äº‘å›¾ï¼ˆå¯èƒ½æ— æ•°æ®æˆ–ç”Ÿæˆé”™è¯¯ï¼‰ã€‚")


def show_skills_majors_page():
    st.title("ğŸ› ï¸ èŒä¸šæŠ€èƒ½ä¸ä¸“ä¸šéœ€æ±‚æ´å¯Ÿ")

    df_jobs_raw = load_json_data(JOBS_FILE)
    if df_jobs_raw.empty: st.warning("æœªèƒ½åŠ è½½èŒä½æ•°æ®ï¼Œè¯·æ£€æŸ¥ `jobs.json` æ–‡ä»¶ã€‚"); st.stop()

    df_jobs = preprocess_jobs_data(df_jobs_raw)

    if df_jobs.empty: st.warning("æ•°æ®é¢„å¤„ç†åä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚"); st.stop()

    # Critical check for 'job_name_and_major_text'
    if 'job_name_and_major_text' not in df_jobs.columns: # Removed 'and not df_jobs.empty' as df_jobs emptiness is checked above
        st.error("Critical Error: 'job_name_and_major_text' is MISSING from df_jobs before skill extraction!")
        st.info("This likely means `preprocess_jobs_data` from utils.py is not creating this column, or an old cached version is being used.")
        st.stop()


    @st.cache_data
    def add_extracted_skills_column(df, text_col, skill_patterns):
        # ... (rest of your function)
        df_copy = df.copy()
        if text_col not in df_copy.columns:
             st.error(f"FATAL in add_extracted_skills_column: Column '{text_col}' not found!")
             st.write("Columns available in df_copy:", list(df_copy.columns))
             st.stop()
        df_copy['extracted_skills_list'] = extract_skills_from_text_series(
            df_copy[text_col],
            skill_regex_patterns=skill_patterns # Ensure this variable is correctly passed
        )
        return df_copy


    if 'SKILL_REGEX_PATTERNS' not in globals() or SKILL_REGEX_PATTERNS is None: # Check SKILL_REGEX_PATTERNS itself
        st.error("SKILL_REGEX_PATTERNS æœªä» utils.py ä¸­æ­£ç¡®å¯¼å…¥æˆ–åˆå§‹åŒ–ï¼")
        st.stop()

    # Call the function to add the skills column
    df_jobs_with_skills = add_extracted_skills_column(df_jobs, 'job_name_and_major_text', SKILL_REGEX_PATTERNS)


    st.sidebar.header("å…¨å±€ç­›é€‰å™¨")
    job_catory_col = 'job_catory' if 'job_catory' in df_jobs_with_skills.columns else None
    degree_name_cat_col = 'degree_name_cat' if 'degree_name_cat' in df_jobs_with_skills.columns else None
    company_property_col = 'company_property' if 'company_property' in df_jobs_with_skills.columns else None

    # Sidebar selectbox for job_catory
    if job_catory_col:
        unique_categories_sidebar_raw = df_jobs_with_skills[job_catory_col].astype(str).dropna().unique() # dropna here
        unique_categories_sidebar_cleaned = sorted([val for val in unique_categories_sidebar_raw if val.lower() != 'nan' and val.strip() != '']) # Ensure stripping
        unique_categories_sidebar = ["æ‰€æœ‰ç±»åˆ«"] + unique_categories_sidebar_cleaned
        selected_category_filter = st.sidebar.selectbox("èŒä½ç±»åˆ«", unique_categories_sidebar, index=0, key="skills_cat_filter")
    else:
        selected_category_filter = "æ‰€æœ‰ç±»åˆ«"
        st.sidebar.warning("åˆ— 'job_catory' ä¸å­˜åœ¨ï¼Œæ— æ³•æŒ‰èŒä½ç±»åˆ«ç­›é€‰ã€‚")

    # Sidebar selectbox for degree_name_cat
    if degree_name_cat_col:
        unique_degrees_sidebar_raw = df_jobs_with_skills[degree_name_cat_col].astype(str).dropna().unique() # dropna here
        unique_degrees_sidebar_cleaned = sorted([val for val in unique_degrees_sidebar_raw if val.lower() != 'nan' and val.strip() != ''])
        unique_degrees_sidebar = ["æ‰€æœ‰å­¦å†"] + unique_degrees_sidebar_cleaned
        selected_degree_filter = st.sidebar.selectbox("å­¦å†è¦æ±‚", unique_degrees_sidebar, index=0, key="skills_deg_filter")
    else:
        selected_degree_filter = "æ‰€æœ‰å­¦å†"
        st.sidebar.warning("åˆ— 'degree_name_cat' ä¸å­˜åœ¨ï¼Œæ— æ³•æŒ‰å­¦å†ç­›é€‰ã€‚")

    # Sidebar selectbox for company_property
    if company_property_col:
        unique_properties_sidebar_raw = df_jobs_with_skills[company_property_col].astype(str).dropna().unique() # dropna here
        unique_properties_sidebar_cleaned = sorted([val for val in unique_properties_sidebar_raw if val.lower() != 'nan' and val.strip() != ''])
        unique_properties_sidebar = ["æ‰€æœ‰æ€§è´¨"] + unique_properties_sidebar_cleaned
        selected_property_filter = st.sidebar.selectbox("å…¬å¸æ€§è´¨", unique_properties_sidebar, index=0, key="skills_prop_filter")
    else:
        selected_property_filter = "æ‰€æœ‰æ€§è´¨"
        st.sidebar.warning("åˆ— 'company_property' ä¸å­˜åœ¨ï¼Œæ— æ³•æŒ‰å…¬å¸æ€§è´¨ç­›é€‰ã€‚")


    filtered_df_with_skills = df_jobs_with_skills.copy()
    if job_catory_col and selected_category_filter != "æ‰€æœ‰ç±»åˆ«":
        filtered_df_with_skills = filtered_df_with_skills[filtered_df_with_skills[job_catory_col] == selected_category_filter]
    if degree_name_cat_col and selected_degree_filter != "æ‰€æœ‰å­¦å†":
        filtered_df_with_skills = filtered_df_with_skills[filtered_df_with_skills[degree_name_cat_col] == selected_degree_filter]
    if company_property_col and selected_property_filter != "æ‰€æœ‰æ€§è´¨":
        filtered_df_with_skills = filtered_df_with_skills[filtered_df_with_skills[company_property_col] == selected_property_filter]

    if filtered_df_with_skills.empty: st.info("æ ¹æ®å½“å‰å…¨å±€ç­›é€‰æ¡ä»¶ï¼Œæ²¡æœ‰åŒ¹é…çš„èŒä½æ•°æ®ã€‚"); st.stop()
    st.info(f"å½“å‰å…¨å±€ç­›é€‰æ¡ä»¶ä¸‹ï¼Œå…±æœ‰ {len(filtered_df_with_skills)} æ¡èŒä½æ•°æ®å‚ä¸åˆ†æã€‚")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”¥ çƒ­é—¨æŠ€èƒ½åˆ†æ", "ğŸ“ çƒ­é—¨ä¸“ä¸šåˆ†æ", "ğŸ·ï¸ å…¬å¸æ ‡ç­¾åˆ†æ", "ğŸ“Š åˆ†ç±»äº¤å‰æ´å¯Ÿ"])

    # ... (rest of your tab content, no changes needed there for this specific error) ...
    # Tab 1: çƒ­é—¨æŠ€èƒ½åˆ†æ (No changes from previous version based on request)
    with tab1:
        st.header("ğŸ”¥ çƒ­é—¨æŠ€èƒ½åˆ†æ (ä»èŒä½åç§°ä¸ä¸“ä¸šéœ€æ±‚æå–)")
        top_n_skills_display = st.slider("é€‰æ‹©çƒ­é—¨æŠ€èƒ½æ˜¾ç¤ºæ•°é‡", 5, 50, 15, key="top_n_skills_display_slider_tab1_v2") # Key updated
        df_extracted_skills_freq = get_skill_frequency(
            filtered_df_with_skills,
            skill_list_column='extracted_skills_list',
            top_n=top_n_skills_display * 2
        )
        if not df_extracted_skills_freq.empty:
            col_skill_bar, col_skill_wc = st.columns([2, 3])
            with col_skill_bar:
                st.subheader(f"Top {top_n_skills_display} çƒ­é—¨æŠ€èƒ½")
                plot_bar_chart(df_extracted_skills_freq.head(top_n_skills_display), 'skill', 'count', title=f"çƒ­é—¨æŠ€èƒ½è¯é¢‘ (Top {top_n_skills_display})", x_label="æŠ€èƒ½", y_label="å‡ºç°æ¬¡æ•°", orientation='h')
            with col_skill_wc:
                st.subheader("çƒ­é—¨æŠ€èƒ½è¯äº‘")
                skill_freq_dict = {row['skill']: row['count'] for _, row in df_extracted_skills_freq.iterrows()}
                wc_skills = generate_wordcloud_from_freq_dict(skill_freq_dict, title="çƒ­é—¨æŠ€èƒ½è¯äº‘", max_words=70)
                display_wordcloud(wc_skills, "çƒ­é—¨æŠ€èƒ½è¯äº‘")
            st.divider()
            st.subheader("æŠ€èƒ½å…±ç°åˆ†æ")
            top_n_cooc_pairs_display = st.slider("é€‰æ‹©æŠ€èƒ½å…±ç°ç»„åˆæ•°é‡", 5, 30, 10, key="top_n_cooc_display_slider_tab1_v2") # Key updated
            min_freq_cooc_input = st.number_input("å…±ç°å¯¹æœ€å°é¢‘ç‡", min_value=1, value=3, step=1, key="min_freq_cooc_input_tab1_v2") # Key updated
            min_skills_text_input = st.number_input("å•æ–‡æœ¬æœ€å°‘æŠ€èƒ½æ•° (ç”¨äºå…±ç°)", min_value=2, value=2, step=1, key="min_skills_text_input_tab1_v2") # Key updated

            df_cooccurrence = get_skill_cooccurrence_optimized(
                filtered_df_with_skills,
                skill_list_column='extracted_skills_list',
                top_n_cooc_pairs=top_n_cooc_pairs_display,
                min_cooc_frequency=min_freq_cooc_input,
                min_skills_in_one_text=min_skills_text_input
            )
            if not df_cooccurrence.empty:
                plot_bar_chart(df_cooccurrence, 'skill_pair', 'count', title=f"çƒ­é—¨æŠ€èƒ½å…±ç° (Top {top_n_cooc_pairs_display} ç»„åˆ)", x_label="æŠ€èƒ½ç»„åˆ", y_label="å…±ç°æ¬¡æ•°", orientation='h')
            else:
                st.info("æœªèƒ½è®¡ç®—å‡ºæ»¡è¶³æ¡ä»¶çš„æŠ€èƒ½å…±ç°æ•°æ®ã€‚å°è¯•è°ƒæ•´ä¸Šæ–¹å‚æ•°ã€‚")
        else:
            st.info("æœªèƒ½æå–åˆ°æŠ€èƒ½ä¿¡æ¯æˆ–æå–çš„æŠ€èƒ½é¢‘ç‡è¿‡ä½ã€‚")

    # Tab 2: çƒ­é—¨ä¸“ä¸šåˆ†æ (No changes from previous version based on request)
    with tab2:
        st.header("ğŸ“ çƒ­é—¨ä¸“ä¸šåˆ†æ")
        top_n_majors_display = st.slider("é€‰æ‹©çƒ­é—¨ä¸“ä¸šæ˜¾ç¤ºæ•°é‡", 5, 30, 10, key="top_n_majors_slider_tab2_v2") # Key updated

        processed_major_col = 'processed_major' if 'processed_major' in filtered_df_with_skills.columns else None
        if not processed_major_col:
            st.warning("åˆ— 'processed_major' ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œæ ‡å‡†åŒ–ä¸“ä¸šåˆ†æã€‚")
        else:
            # Filter out generic major names before counting
            df_majors_for_count = filtered_df_with_skills[
                ~filtered_df_with_skills[processed_major_col].astype(str).str.lower().isin(['æœªçŸ¥', 'å…¶ä»–ä¸“ä¸š', 'ä¸é™ä¸“ä¸š', 'ä¸é™', 'nan', ''])
            ]
            df_std_majors_counts = get_top_n_counts(
                df_majors_for_count,
                processed_major_col,
                top_n=top_n_majors_display * 2
            )

            if not df_std_majors_counts.empty:
                col_major_bar, col_major_wc = st.columns([2, 3])
                with col_major_bar:
                    st.subheader(f"Top {top_n_majors_display} æ ‡å‡†åŒ–ä¸“ä¸šéœ€æ±‚")
                    plot_bar_chart(df_std_majors_counts.head(top_n_majors_display),
                                   processed_major_col, 'count',
                                   title=f"çƒ­é—¨æ ‡å‡†åŒ–ä¸“ä¸š (Top {top_n_majors_display})",
                                   x_label="ä¸“ä¸šåç§° (æ ‡å‡†åŒ–)", y_label="èŒä½æ•°é‡", orientation='h')
                with col_major_wc:
                    st.subheader("æ ‡å‡†åŒ–ä¸“ä¸šè¯äº‘")
                    std_major_freq_dict = {row[processed_major_col]: row['count'] for _, row in df_std_majors_counts.iterrows()}
                    wc_std_majors = generate_wordcloud_from_freq_dict(std_major_freq_dict, title="æ ‡å‡†åŒ–ä¸“ä¸šè¯äº‘", max_words=60)
                    display_wordcloud(wc_std_majors, "æ ‡å‡†åŒ–ä¸“ä¸šè¯äº‘")

                st.divider()
                st.subheader("ğŸ¯ ä¸“ä¸šéœ€æ±‚æ·±åº¦æ´å¯Ÿ")

                if job_catory_col:
                    st.write("**ä¸åŒèŒä½ç±»åˆ« Top 3 çƒ­é—¨ä¸“ä¸š**")
                    top_categories_for_major_analysis = filtered_df_with_skills[job_catory_col].value_counts().nlargest(5).index.tolist()
                    if top_categories_for_major_analysis:
                        major_by_category_list = []
                        for cat in top_categories_for_major_analysis:
                            df_cat = filtered_df_with_skills[filtered_df_with_skills[job_catory_col] == cat]
                            # Filter generic majors for each category
                            df_cat_majors_filtered = df_cat[
                                ~df_cat[processed_major_col].astype(str).str.lower().isin(['æœªçŸ¥', 'å…¶ä»–ä¸“ä¸š', 'ä¸é™ä¸“ä¸š', 'ä¸é™', 'nan', ''])
                            ]
                            if not df_cat_majors_filtered.empty:
                                df_cat_majors = get_top_n_counts(
                                    df_cat_majors_filtered,
                                    processed_major_col,
                                    top_n=3
                                )
                                if not df_cat_majors.empty:
                                    df_cat_majors[job_catory_col] = cat
                                    major_by_category_list.append(df_cat_majors)

                        if major_by_category_list:
                            df_major_by_category_plot = pd.concat(major_by_category_list)
                            if not df_major_by_category_plot.empty:
                                fig_major_cat = px.bar(df_major_by_category_plot,
                                                       x=processed_major_col, y="count", color=job_catory_col,
                                                       barmode="group", title="éƒ¨åˆ†çƒ­é—¨èŒä½ç±»åˆ«çš„ Top 3 ä¸“ä¸šéœ€æ±‚",
                                                       labels={processed_major_col: "ä¸“ä¸š", "count": "èŒä½æ•°", job_catory_col: "èŒä½ç±»åˆ«"})
                                fig_major_cat.update_layout(xaxis_tickangle=-45)
                                st.plotly_chart(fig_major_cat, use_container_width=True)
                            else: st.caption("æœªèƒ½ç”ŸæˆèŒä½ç±»åˆ«ä¸ä¸“ä¸šå¯¹æ¯”å›¾ã€‚")
                        else: st.caption("æœªèƒ½æ”¶é›†åˆ°æŒ‰èŒä½ç±»åˆ«åˆ’åˆ†çš„ä¸“ä¸šæ•°æ®ã€‚")
                    else: st.caption("æ— è¶³å¤Ÿçš„èŒä½ç±»åˆ«æ•°æ®è¿›è¡Œä¸“ä¸šå¯¹æ¯”åˆ†æã€‚")
                else: st.caption(f"åˆ— '{job_catory_col}' ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡ŒèŒä½ç±»åˆ«ä¸ä¸“ä¸šå¯¹æ¯”åˆ†æã€‚")

                if 'avg_month_pay' in filtered_df_with_skills.columns and callable(globals().get('get_average_salary')):
                    st.write("**çƒ­é—¨ä¸“ä¸šçš„å¹³å‡æœˆè–ª**")
                    top_major_names = df_std_majors_counts.head(top_n_majors_display)[processed_major_col].tolist()
                    df_salary_for_top_majors = filtered_df_with_skills[
                        filtered_df_with_skills[processed_major_col].isin(top_major_names) &
                        (filtered_df_with_skills['avg_month_pay'] > 0) # Filter for valid salaries
                    ]

                    if not df_salary_for_top_majors.empty:
                        df_avg_salary_by_major = get_average_salary(df_salary_for_top_majors, processed_major_col) # Assumes get_average_salary handles empty groups
                        if not df_avg_salary_by_major.empty:
                            df_avg_salary_by_major = df_avg_salary_by_major.sort_values(by='average_salary', ascending=False).head(top_n_majors_display)
                            plot_bar_chart(df_avg_salary_by_major, processed_major_col, 'average_salary',
                                           title=f"Top {top_n_majors_display} ä¸“ä¸šå¹³å‡æœˆè–ª",
                                           x_label="ä¸“ä¸šåç§°", y_label="å¹³å‡æœˆè–ª (å…ƒ)", orientation='h') # Ensure units are consistent
                        else: st.caption("æœªèƒ½è®¡ç®—çƒ­é—¨ä¸“ä¸šçš„å¹³å‡è–ªèµ„ (å¯èƒ½æ•°æ®ä¸è¶³æˆ–å…¨ä¸º0)ã€‚")
                    else: st.caption("æ— è¶³å¤Ÿæ•°æ® (å«æœ‰æ•ˆè–ªèµ„) è®¡ç®—çƒ­é—¨ä¸“ä¸šçš„å¹³å‡è–ªèµ„ã€‚")
                else: st.caption("ç¼ºå°‘è–ªèµ„æ•°æ®æˆ– `get_average_salary` å‡½æ•°æ— æ³•è¿›è¡Œè–ªèµ„åˆ†æã€‚")
            else:
                st.info("æœªèƒ½ç»Ÿè®¡åˆ°æ ‡å‡†åŒ–ä¸“ä¸šéœ€æ±‚ã€‚")

    # Tab 3: å…¬å¸æ ‡ç­¾åˆ†æ
    with tab3:
        st.header("ğŸ·ï¸ å…¬å¸ç¦åˆ©/æ ‡ç­¾åˆ†æ")
        tags_list_col = 'tags_list' if 'tags_list' in filtered_df_with_skills.columns else None
        if not tags_list_col:
            st.warning("åˆ— 'tags_list' ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œå…¬å¸æ ‡ç­¾åˆ†æã€‚")
        else:
            top_n_tags_display = st.slider("é€‰æ‹©çƒ­é—¨å…¬å¸æ ‡ç­¾æ˜¾ç¤ºæ•°é‡", 5, 30, 10, key="top_n_tags_slider_tab3_v2") # Key updated
            df_tags_counts = get_word_counts_from_list_column(
                filtered_df_with_skills, tags_list_col, top_n=top_n_tags_display * 2, exclude_items={'æ— ', 'nan', ''} # Added more excludes
            )

            if not df_tags_counts.empty:
                col_tag_bar, col_tag_wc = st.columns([2, 3])
                with col_tag_bar:
                    st.subheader(f"Top {top_n_tags_display} å…¬å¸æ ‡ç­¾")
                    plot_bar_chart(df_tags_counts.head(top_n_tags_display), 'item', 'count',
                                   title=f"çƒ­é—¨å…¬å¸æ ‡ç­¾ (Top {top_n_tags_display})",
                                   x_label="å…¬å¸æ ‡ç­¾", y_label="å‡ºç°æ¬¡æ•°", orientation='h')
                with col_tag_wc:
                    st.subheader("å…¬å¸æ ‡ç­¾è¯äº‘")
                    tag_freq_dict = {row['item']: row['count'] for _, row in df_tags_counts.iterrows()}
                    wc_tags = generate_wordcloud_from_freq_dict(tag_freq_dict, title="å…¬å¸æ ‡ç­¾è¯äº‘", max_words=60)
                    display_wordcloud(wc_tags, "å…¬å¸æ ‡ç­¾è¯äº‘")

                st.divider()
                st.subheader("ğŸ·ï¸ å…¬å¸æ ‡ç­¾æ·±åº¦æ´å¯Ÿ")

                st.write("**çƒ­é—¨å…¬å¸æ ‡ç­¾å…±ç°** (Top 5 ç»„åˆ)")
                temp_df_for_tag_cooc = filtered_df_with_skills[[tags_list_col]].copy()
                temp_df_for_tag_cooc.rename(columns={tags_list_col: 'cooc_items'}, inplace=True) # Use a generic name for the function
                df_tag_cooccurrence = get_skill_cooccurrence_optimized( # Reusing skill co-occurrence logic here
                    temp_df_for_tag_cooc,
                    skill_list_column='cooc_items', # Changed to generic name
                    top_n_cooc_pairs=5,
                    min_cooc_frequency=2,
                    min_skills_in_one_text=2 # This means min 2 tags for a job to be considered for co-occurrence
                )
                if not df_tag_cooccurrence.empty:
                    plot_bar_chart(df_tag_cooccurrence, 'skill_pair', 'count', # skill_pair is the output column name from the function
                                   title="çƒ­é—¨å…¬å¸æ ‡ç­¾å…±ç°", x_label="æ ‡ç­¾ç»„åˆ",
                                   y_label="å…±ç°æ¬¡æ•°", orientation='h')
                else: st.caption("æœªèƒ½è®¡ç®—å‡ºæ»¡è¶³æ¡ä»¶çš„æ ‡ç­¾å…±ç°æ•°æ®ã€‚")

                company_scale_cat_col_tab3 = 'company_scale_cat' if 'company_scale_cat' in filtered_df_with_skills.columns else None
                if company_scale_cat_col_tab3 and not df_tags_counts.empty:
                    st.write("**ç‰¹å®šæ ‡ç­¾ä¸‹çš„å…¬å¸è§„æ¨¡åˆ†å¸ƒ**")

                    available_tags_for_selection = df_tags_counts['item'].tolist()
                    selected_tag_for_scale_analysis = st.selectbox(
                        "é€‰æ‹©ä¸€ä¸ªæ ‡ç­¾æŸ¥çœ‹å…¶å…¬å¸è§„æ¨¡åˆ†å¸ƒ:",
                        options=available_tags_for_selection,
                        index=0 if available_tags_for_selection else -1, # Handle empty options
                        key="tag_scale_dist_selector_tab3_v2"
                    )

                    if selected_tag_for_scale_analysis: # Ensure a tag is selected
                        df_with_selected_tag = filtered_df_with_skills[
                            filtered_df_with_skills[tags_list_col].apply(lambda x: selected_tag_for_scale_analysis in x if isinstance(x, (list, tuple)) else False) # Check type
                        ]
                        if not df_with_selected_tag.empty and df_with_selected_tag[company_scale_cat_col_tab3].notna().any(): # Check for scale data
                            scale_dist = df_with_selected_tag[company_scale_cat_col_tab3].value_counts().reset_index()
                            scale_dist.columns = [company_scale_cat_col_tab3, 'count']
                            fig_scale_dist = px.pie(scale_dist, names=company_scale_cat_col_tab3, values='count',
                                                    title=f"å«æ ‡ç­¾ '{selected_tag_for_scale_analysis}' çš„å…¬å¸è§„æ¨¡åˆ†å¸ƒ", hole=0.3)
                            st.plotly_chart(fig_scale_dist, use_container_width=True)
                        else: st.caption(f"æ²¡æœ‰å…¬å¸åŒæ—¶æ‹¥æœ‰æ ‡ç­¾ '{selected_tag_for_scale_analysis}' å’Œæœ‰æ•ˆçš„å…¬å¸è§„æ¨¡ä¿¡æ¯ã€‚")
                elif df_tags_counts.empty:
                     st.caption("æ— çƒ­é—¨æ ‡ç­¾å¯ä¾›åˆ†æå…¬å¸è§„æ¨¡ã€‚")
                elif not company_scale_cat_col_tab3:
                    st.caption(f"åˆ— 'company_scale_cat' ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œå…¬å¸è§„æ¨¡ä¸æ ‡ç­¾å…³è”åˆ†æã€‚")
            else:
                st.info("æœªèƒ½ç»Ÿè®¡åˆ°å…¬å¸æ ‡ç­¾ä¿¡æ¯ã€‚")

    # Tab 4: åˆ†ç±»äº¤å‰æ´å¯Ÿ
    with tab4:
        st.header("ğŸ“Š åˆ†ç±»äº¤å‰æ´å¯Ÿ")
        st.write("é€‰æ‹©ä¸€ä¸ªä¸»è¦åˆ†æç»´åº¦ï¼Œç„¶åæ¢ç´¢ä¸åŒæŒ‡æ ‡ä¸‹çš„æ•°æ®æ´å¯Ÿã€‚")

        analysis_dimensions = {
            "èŒä½ç±»åˆ«": job_catory_col,
            "å­¦å†è¦æ±‚": degree_name_cat_col,
            "å…¬å¸æ€§è´¨": company_property_col,
            "çœä»½": "province_clean" if "province_clean" in filtered_df_with_skills.columns else None,
            "åŸå¸‚": "city_clean" if "city_clean" in filtered_df_with_skills.columns else None,
            "å…¬å¸è§„æ¨¡": 'company_scale_cat' if 'company_scale_cat' in filtered_df_with_skills.columns else None
        }
        valid_analysis_dimensions = {k: v for k, v in analysis_dimensions.items() if v is not None and filtered_df_with_skills[v].notna().any()} # Also check if col has data

        if not valid_analysis_dimensions:
            st.warning("æ²¡æœ‰å¯ç”¨çš„ä¸»è¦åˆ†æç»´åº¦ï¼ˆç›¸å…³åˆ—å¯èƒ½ç¼ºå¤±æˆ–æ— æ•°æ®ï¼‰ã€‚")
            st.stop()

        selected_main_dim_label = st.selectbox(
            "é€‰æ‹©ä¸»è¦åˆ†æç»´åº¦:",
            options=list(valid_analysis_dimensions.keys()),
            index=0,
            key="main_dim_selector_tab4_v2" # Key updated
        )
        main_dim_col_tab4 = valid_analysis_dimensions[selected_main_dim_label]

        unique_values_raw_tab4 = filtered_df_with_skills[main_dim_col_tab4].astype(str).dropna().unique() # dropna here
        unique_values_in_dim_tab4 = sorted([val for val in unique_values_raw_tab4 if val.lower() != 'nan' and val.strip() != '']) # Clean again


        if len(unique_values_in_dim_tab4) > 25 and main_dim_col_tab4 not in ["province_clean", "city_clean"]:
            # For non-geo dimensions with many values, show top N
            top_n_values_df = get_top_n_counts(filtered_df_with_skills.dropna(subset=[main_dim_col_tab4]), main_dim_col_tab4, top_n=15)
            selectable_values_tab4 = top_n_values_df[main_dim_col_tab4].astype(str).tolist()

            if main_dim_col_tab4 == degree_name_cat_col: # Specific cleaning for degree 'nan'
                selectable_values_tab4 = [val for val in selectable_values_tab4 if val.lower() != 'nan']
            st.info(f"ç»´åº¦ '{selected_main_dim_label}' çš„é€‰é¡¹è¿‡å¤šï¼ˆ{len(unique_values_in_dim_tab4)}ä¸ªï¼‰ï¼Œä»…å±•ç¤ºæœ€å¸¸è§çš„15ä¸ªã€‚")
        elif not unique_values_in_dim_tab4:
            st.warning(f"ç»´åº¦ '{selected_main_dim_label}' æ²¡æœ‰æœ‰æ•ˆå€¼å¯ä¾›é€‰æ‹©ã€‚")
            selectable_values_tab4 = []
        else:
            selectable_values_tab4 = unique_values_in_dim_tab4

        selected_specific_values = st.multiselect(
            f"é€‰æ‹© '{selected_main_dim_label}' ä¸‹çš„å…·ä½“åˆ†ç±»è¿›è¡Œåˆ†æ/å¯¹æ¯” (å¯å¤šé€‰):",
            options=selectable_values_tab4,
            default=selectable_values_tab4[0] if selectable_values_tab4 else None,
            key="specific_value_selector_tab4_v2" # Key updated
        )

        if not selected_specific_values:
            st.info(f"è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ª '{selected_main_dim_label}' ä¸‹çš„å…·ä½“åˆ†ç±»ã€‚")
        else:
            df_analysis_base_tab4 = filtered_df_with_skills[
                filtered_df_with_skills[main_dim_col_tab4].isin(selected_specific_values)
            ].copy()

            if df_analysis_base_tab4.empty:
                st.warning("æ ¹æ®å½“å‰é€‰æ‹©ï¼Œæ²¡æœ‰å¯ä¾›åˆ†æçš„æ•°æ®ã€‚")
            else:
                analysis_content_options = [
                    "çƒ­é—¨æŠ€èƒ½å¯¹æ¯”",
                    "çƒ­é—¨ä¸“ä¸šå¯¹æ¯”",
                    "è–ªèµ„æ°´å¹³å¯¹æ¯”",
                    "é«˜è–ªæŠ€èƒ½ç”»åƒ"
                ]
                content_tabs = st.tabs(analysis_content_options)

                with content_tabs[0]: # çƒ­é—¨æŠ€èƒ½å¯¹æ¯”
                    st.subheader(f"ğŸ› ï¸ '{', '.join(selected_specific_values)}' çš„çƒ­é—¨æŠ€èƒ½å¯¹æ¯”")
                    skill_data_for_plot = []
                    top_n_skills_cat = st.slider("æ¯ä¸ªåˆ†ç±»æ˜¾ç¤ºTop NæŠ€èƒ½", 3, 15, 5, key="top_n_skills_cat_tab4_slider_v2") # Key updated

                    for val in selected_specific_values:
                        df_val_specific = df_analysis_base_tab4[df_analysis_base_tab4[main_dim_col_tab4] == val]
                        if not df_val_specific.empty and 'extracted_skills_list' in df_val_specific.columns:
                            df_skills_freq = get_skill_frequency(df_val_specific, 'extracted_skills_list', top_n=top_n_skills_cat)
                            if not df_skills_freq.empty:
                                df_skills_freq[main_dim_col_tab4] = val
                                skill_data_for_plot.append(df_skills_freq)

                    if skill_data_for_plot:
                        df_plot_skills = pd.concat(skill_data_for_plot)
                        if not df_plot_skills.empty:
                            fig_skills = px.bar(df_plot_skills, x='skill', y='count', color=main_dim_col_tab4,
                                                barmode='group', title=f"çƒ­é—¨æŠ€èƒ½å¯¹æ¯” (Top {top_n_skills_cat})",
                                                labels={'skill': 'æŠ€èƒ½', 'count': 'èŒä½æ•°', main_dim_col_tab4: selected_main_dim_label})
                            fig_skills.update_layout(xaxis_tickangle=-45)
                            st.plotly_chart(fig_skills, use_container_width=True)

                            if 1 < len(selected_specific_values) <= 5 and top_n_skills_cat <=10:
                                st.write("**æŠ€èƒ½éœ€æ±‚é›·è¾¾å›¾å¯¹æ¯”**")
                                all_top_skills_union = df_plot_skills['skill'].unique()
                                radar_df_list = []
                                for val in selected_specific_values:
                                    df_val_skills = df_plot_skills[df_plot_skills[main_dim_col_tab4] == val]
                                    data_row = {main_dim_col_tab4: val}
                                    for skill_item in all_top_skills_union:
                                        count = df_val_skills[df_val_skills['skill'] == skill_item]['count'].sum()
                                        data_row[skill_item] = count
                                    radar_df_list.append(data_row)
                                df_radar_data = pd.DataFrame(radar_df_list)
                                if not df_radar_data.empty and len(all_top_skills_union) >=3 : # Radar needs at least 3 points
                                    df_radar_melted = df_radar_data.melt(id_vars=main_dim_col_tab4, value_vars=all_top_skills_union,
                                                                        var_name='skill', value_name='count')
                                    try:
                                        fig_radar_skills = px.line_polar(df_radar_melted, r='count', theta='skill',
                                                                        color=main_dim_col_tab4, line_close=True,
                                                                        title="æŠ€èƒ½éœ€æ±‚å¼ºåº¦é›·è¾¾å›¾")
                                        st.plotly_chart(fig_radar_skills, use_container_width=True)
                                    except Exception as e_radar: st.caption(f"æ— æ³•ç”ŸæˆæŠ€èƒ½é›·è¾¾å›¾: {e_radar} (å¯èƒ½thetaå€¼ä¸è¶³)")
                                else: st.caption("æ— è¶³å¤Ÿæ•°æ® (è‡³å°‘3ç§æŠ€èƒ½) ç”ŸæˆæŠ€èƒ½é›·è¾¾å›¾ã€‚")
                        else: st.info("åœ¨æ‰€é€‰åˆ†ç±»ä¸‹æœªèƒ½æå–åˆ°è¶³å¤Ÿçš„æŠ€èƒ½æ•°æ®è¿›è¡Œå¯¹æ¯”ã€‚")
                    else: st.info("åœ¨æ‰€é€‰åˆ†ç±»ä¸‹æœªèƒ½æå–åˆ°æŠ€èƒ½æ•°æ®ã€‚")

                with content_tabs[1]: # çƒ­é—¨ä¸“ä¸šå¯¹æ¯”
                    st.subheader(f"ğŸ“ '{', '.join(selected_specific_values)}' çš„çƒ­é—¨ä¸“ä¸šå¯¹æ¯”")
                    major_data_for_plot = []
                    top_n_majors_cat = st.slider("æ¯ä¸ªåˆ†ç±»æ˜¾ç¤ºTop Nä¸“ä¸š", 3, 15, 5, key="top_n_majors_cat_tab4_slider_v2") # Key updated

                    current_processed_major_col_tab4 = 'processed_major'
                    if current_processed_major_col_tab4 not in df_analysis_base_tab4.columns:
                        st.warning(f"åˆ— '{current_processed_major_col_tab4}' ä¸å­˜åœ¨äºåˆ†ææ•°æ®é›†ä¸­ã€‚")
                    else:
                        for val in selected_specific_values:
                            df_val_specific = df_analysis_base_tab4[df_analysis_base_tab4[main_dim_col_tab4] == val]
                            # Filter generic majors
                            df_val_specific_filtered = df_val_specific[
                                ~df_val_specific[current_processed_major_col_tab4].astype(str).str.lower().isin(['æœªçŸ¥', 'å…¶ä»–ä¸“ä¸š', 'ä¸é™ä¸“ä¸š', 'ä¸é™', 'nan', ''])
                            ]
                            if not df_val_specific_filtered.empty:
                                df_majors_freq = get_top_n_counts(df_val_specific_filtered, current_processed_major_col_tab4, top_n=top_n_majors_cat)
                                if not df_majors_freq.empty:
                                    df_majors_freq[main_dim_col_tab4] = val
                                    major_data_for_plot.append(df_majors_freq)

                        if major_data_for_plot:
                            df_plot_majors = pd.concat(major_data_for_plot)
                            if not df_plot_majors.empty:
                                fig_majors = px.bar(df_plot_majors, x=current_processed_major_col_tab4, y='count', color=main_dim_col_tab4,
                                                    barmode='group', title=f"çƒ­é—¨ä¸“ä¸šå¯¹æ¯” (Top {top_n_majors_cat})",
                                                    labels={current_processed_major_col_tab4: 'ä¸“ä¸š (æ ‡å‡†åŒ–)', 'count': 'èŒä½æ•°', main_dim_col_tab4: selected_main_dim_label})
                                fig_majors.update_layout(xaxis_tickangle=-45)
                                st.plotly_chart(fig_majors, use_container_width=True)
                            else: st.info("åœ¨æ‰€é€‰åˆ†ç±»ä¸‹æœªèƒ½ç»Ÿè®¡åˆ°è¶³å¤Ÿçš„ä¸“ä¸šæ•°æ®è¿›è¡Œå¯¹æ¯”ã€‚")
                        else: st.info("åœ¨æ‰€é€‰åˆ†ç±»ä¸‹æœªèƒ½ç»Ÿè®¡åˆ°ä¸“ä¸šæ•°æ®ã€‚")

                with content_tabs[2]: # è–ªèµ„æ°´å¹³å¯¹æ¯”
                    st.subheader(f"ğŸ’° '{', '.join(selected_specific_values)}' çš„è–ªèµ„æ°´å¹³å¯¹æ¯”")
                    if 'avg_month_pay' not in df_analysis_base_tab4.columns:
                        st.warning("æ•°æ®ä¸­ç¼ºå°‘ 'avg_month_pay' åˆ—ï¼Œæ— æ³•è¿›è¡Œè–ªèµ„åˆ†æã€‚")
                    else:
                        df_salary_analysis = df_analysis_base_tab4[df_analysis_base_tab4['avg_month_pay'] > 0].copy()
                        if not df_salary_analysis.empty:
                            avg_salary_data = df_salary_analysis.groupby(main_dim_col_tab4, observed=True)['avg_month_pay'].agg(['mean', 'median', 'count']).reset_index()
                            avg_salary_data.columns = [main_dim_col_tab4, 'average_salary_k', 'median_salary_k', 'job_count_with_salary']
                            # avg_salary_data['average_salary_k'] already in K
                            avg_salary_data = avg_salary_data.sort_values(by='average_salary_k', ascending=False)

                            if not avg_salary_data.empty:
                                fig_avg_salary = px.bar(avg_salary_data, x=main_dim_col_tab4, y='average_salary_k', color=main_dim_col_tab4,
                                                        title="å¹³å‡æœˆè–ªå¯¹æ¯” (K)",
                                                        labels={main_dim_col_tab4: selected_main_dim_label, 'average_salary_k': 'å¹³å‡æœˆè–ª (K/æœˆ)'})
                                st.plotly_chart(fig_avg_salary, use_container_width=True)

                            # df_salary_analysis['avg_month_pay_k'] already in K
                            fig_box_salary = px.box(df_salary_analysis, x=main_dim_col_tab4, y='avg_month_pay', color=main_dim_col_tab4, # y='avg_month_pay' which is already in K
                                                    title="æœˆè–ªåˆ†å¸ƒå¯¹æ¯” (K)",
                                                    labels={main_dim_col_tab4: selected_main_dim_label, 'avg_month_pay': 'æœˆè–ª (K/æœˆ)'})
                            st.plotly_chart(fig_box_salary, use_container_width=True)
                        else: st.info("åœ¨æ‰€é€‰åˆ†ç±»ä¸‹æ²¡æœ‰æœ‰æ•ˆçš„è–ªèµ„æ•°æ®ã€‚")

                with content_tabs[3]: # é«˜è–ªæŠ€èƒ½ç”»åƒ
                    st.subheader(f"ğŸ’ é«˜è–ªæŠ€èƒ½ç”»åƒ")

                    target_category_value_tab4 = None
                    if not selected_specific_values:
                        st.info("è¯·å…ˆåœ¨ä¸Šæ–¹é€‰æ‹©è‡³å°‘ä¸€ä¸ªå…·ä½“åˆ†ç±»ã€‚")
                    elif len(selected_specific_values) == 1:
                        target_category_value_tab4 = selected_specific_values[0]
                        st.markdown(f"### æ·±å…¥åˆ†æ: **{target_category_value_tab4}**")
                    else:
                        st.write(f"æ‚¨å·²é€‰æ‹©äº†å¤šä¸ª '{selected_main_dim_label}' åˆ†ç±»: {', '.join(selected_specific_values)}")
                        target_category_value_tab4 = st.selectbox(
                            f"è¯·é€‰æ‹©å…¶ä¸­ä¸€ä¸ª '{selected_main_dim_label}' åˆ†ç±»è¿›è¡Œè¯¦ç»†çš„é«˜è–ªæŠ€èƒ½ç”»åƒåˆ†æ:",
                            options=selected_specific_values,
                            index=0,
                            key="single_cat_for_high_skill_analysis_tab4_v2" # Key updated
                        )
                        if target_category_value_tab4: # Ensure a selection is made from selectbox
                             st.markdown(f"### æ·±å…¥åˆ†æ: **{target_category_value_tab4}**")


                    if target_category_value_tab4:
                        df_target_cat_tab4 = df_analysis_base_tab4[
                            df_analysis_base_tab4[main_dim_col_tab4] == target_category_value_tab4
                        ].copy()

                        if 'avg_month_pay' not in df_target_cat_tab4.columns:
                             st.warning(f"åˆ†ç±» '{target_category_value_tab4}' çš„æ•°æ®ä¸­ç¼ºå°‘ 'avg_month_pay' åˆ—ã€‚")
                        elif 'extracted_skills_list' not in df_target_cat_tab4.columns:
                             st.warning(f"åˆ†ç±» '{target_category_value_tab4}' çš„æ•°æ®ä¸­ç¼ºå°‘ 'extracted_skills_list' åˆ—ã€‚")
                        else:
                            df_target_cat_filtered_salary = df_target_cat_tab4[df_target_cat_tab4['avg_month_pay'] > 0].copy()

                            if not df_target_cat_filtered_salary.empty:
                                top_skills_in_cat_df = get_skill_frequency(df_target_cat_filtered_salary, 'extracted_skills_list', top_n=20)
                                if not top_skills_in_cat_df.empty:
                                    top_skills_list = top_skills_in_cat_df['skill'].tolist()
                                    skill_salary_comparison = []
                                    overall_avg_salary_in_cat_k = df_target_cat_filtered_salary['avg_month_pay'].mean() # Already in K

                                    for skill_item in top_skills_list:
                                        df_with_skill = df_target_cat_filtered_salary[
                                            df_target_cat_filtered_salary['extracted_skills_list'].apply(lambda x: skill_item in x if isinstance(x, (list, tuple)) else False) # Check type
                                        ]
                                        if not df_with_skill.empty:
                                            avg_salary_with_skill_k = df_with_skill['avg_month_pay'].mean() # Already K
                                            median_salary_with_skill_k = df_with_skill['avg_month_pay'].median() # Already K
                                            job_count_with_skill = len(df_with_skill)
                                            salary_premium_vs_cat_avg = 0
                                            if overall_avg_salary_in_cat_k > 0: # Ensure no division by zero
                                                salary_premium_vs_cat_avg = ((avg_salary_with_skill_k - overall_avg_salary_in_cat_k) / overall_avg_salary_in_cat_k) * 100

                                            skill_salary_comparison.append({
                                                "æŠ€èƒ½": skill_item,
                                                "å¹³å‡æœˆè–ª(K)": avg_salary_with_skill_k,
                                                "ä¸­ä½æ•°æœˆè–ª(K)": median_salary_with_skill_k,
                                                "èŒä½æ•°": job_count_with_skill,
                                                f"æº¢ä»·(vs '{target_category_value_tab4}'å¹³å‡)": salary_premium_vs_cat_avg
                                            })

                                    if skill_salary_comparison:
                                        df_skill_salary = pd.DataFrame(skill_salary_comparison)
                                        df_skill_salary = df_skill_salary.sort_values(by=f"æº¢ä»·(vs '{target_category_value_tab4}'å¹³å‡)", ascending=False)
                                        st.write(f"**'{target_category_value_tab4}' åˆ†ç±»ä¸‹ï¼Œçƒ­é—¨æŠ€èƒ½å¯¹åº”çš„è–ªèµ„è¡¨ç°ï¼š**")
                                        format_dict_tab4 = {
                                            "å¹³å‡æœˆè–ª(K)": "{:,.1f}", # No need for " K" suffix, it's in the column name
                                            "ä¸­ä½æ•°æœˆè–ª(K)": "{:,.1f}",
                                            f"æº¢ä»·(vs '{target_category_value_tab4}'å¹³å‡)": "{:.1f}%"
                                        }
                                        st.dataframe(df_skill_salary.style.format(format_dict_tab4), use_container_width=True)
                                        df_plot_premium = df_skill_salary.nlargest(10, f"æº¢ä»·(vs '{target_category_value_tab4}'å¹³å‡)")
                                        if not df_plot_premium.empty:
                                            fig_premium = px.bar(df_plot_premium, x="æŠ€èƒ½", y=f"æº¢ä»·(vs '{target_category_value_tab4}'å¹³å‡)",
                                                                 color="æŠ€èƒ½", title=f"'{target_category_value_tab4}' å†…è–ªèµ„æº¢ä»·æœ€é«˜çš„ Top 10 æŠ€èƒ½",
                                                                 labels={"æŠ€èƒ½":"æŠ€èƒ½", f"æº¢ä»·(vs '{target_category_value_tab4}'å¹³å‡)":"è–ªèµ„æº¢ä»· (%)"})
                                            fig_premium.update_layout(showlegend=False)
                                            st.plotly_chart(fig_premium, use_container_width=True)
                                    else:
                                        st.info(f"æœªèƒ½è®¡ç®— '{target_category_value_tab4}' åˆ†ç±»ä¸‹çš„æŠ€èƒ½è–ªèµ„å…³è”æ•°æ®ã€‚")
                                else:
                                    st.info(f"æœªèƒ½æå– '{target_category_value_tab4}' åˆ†ç±»ä¸‹çš„çƒ­é—¨æŠ€èƒ½ã€‚")
                            else:
                                st.info(f"åœ¨ '{target_category_value_tab4}' åˆ†ç±»ä¸‹æ²¡æœ‰å¸¦æœ‰æ•ˆè–ªèµ„ï¼ˆå¤§äº0ï¼‰çš„èŒä½æ•°æ®ã€‚")
                    else:
                        st.info("è¯·ä»ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªåˆ†ç±»è¿›è¡Œé«˜è–ªæŠ€èƒ½ç”»åƒåˆ†æã€‚")


# --- sys.path modification needs to be at the very top of the script, before any streamlit command.
# --- However, the imports from utils.py are more critical.
# --- The typical way to run a multipage app is `streamlit run Main_App.py` from the project root.
# --- If Main_App.py handles sys.path correctly, pages should not need to modify it.

if __name__ == "__main__":
    # The set_page_config call has been moved to the top of the script.
    # This block is fine for directly running this page, but in a multipage app,
    # Streamlit calls the functions in page files directly.
    show_skills_majors_page()